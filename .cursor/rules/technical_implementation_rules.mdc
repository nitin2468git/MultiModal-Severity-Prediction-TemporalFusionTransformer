# Technical Implementation Rules

## Architecture Constraints
- All models must inherit from `torch.nn.Module`
- Must implement `forward()` method with exact input/output shapes specified
- Models must work on both CPU and GPU (use `.to(device)`)
- Ensure all model parameters are properly connected for backpropagation
- Only use PyTorch and standard Python libraries (no additional ML frameworks)

## Performance Requirements
- MLP Planner: < 0.2 longitudinal error, < 0.6 lateral error
- Transformer Planner: < 0.2 longitudinal error, < 0.6 lateral error  
- CNN Planner: < 0.30 longitudinal error, < 0.45 lateral error
- Models should train within reasonable time (< 2 hours on standard GPU)
- Models must fit in 8GB GPU memory

## Model-Specific Constraints
- MLP/Transformer: Must use `track_left` and `track_right` as input (no images)
- CNN: Must use RGB images as input (no ground truth lane data)
- Fixed dimensions: `n_track=10`, `n_waypoints=3` (non-configurable)
- Transformer Architecture: Must use cross-attention with learned query embeddings

# Code Organization Rules

## File Structure
```
homework/
├── models.py          # All model implementations
├── train_planner.py   # Training pipeline
├── metrics.py         # Evaluation metrics
├── datasets/          # Data loading (don't modify)
└── supertux_utils/   # Visualization (optional)
```

## Naming Conventions
- Classes: PascalCase (`MLPPlanner`, `TransformerPlanner`, `CNNPlanner`)
- Functions: snake_case (`train_model`, `evaluate_model`)
- Variables: snake_case (`batch_size`, `learning_rate`)
- Constants: UPPER_SNAKE_CASE (`NUM_WAYPOINTS`, `NUM_TRACK_POINTS`)
- Model Files: Use descriptive names (`mlp_planner.pth`, `transformer_planner.pth`)

## Code Organization
- Group imports (standard library, third-party, local)
- Class structure: `__init__`, `forward`, helper methods
- Training pipeline: Separate functions for data loading, training loop, evaluation
- Use dictionaries or dataclasses for hyperparameters

## Documentation Requirements
- Class docstrings: Describe model architecture and expected inputs/outputs
- Function docstrings: Include parameter types, return types, and brief description
- Add inline comments for non-obvious operations
- Document any custom data transformations or model modifications

# Evaluation Rules

## Testing Procedures
- Must run `python3 -m grader homework -v` before submission
- Test submission bundle with `python3 -m grader $UT_ID.zip`
- Ensure saved models can be loaded and used for inference
- Verify models work with provided dataset structure

## Grading Criteria
- Models must meet specified error thresholds
- Clean, readable, well-documented code
- Complete training pipeline implementation from scratch
- Correct implementation of specified architectures
- Robust handling of edge cases and failures

## Evaluation Metrics
- Longitudinal Error: Absolute difference in forward direction (speed prediction)
- Lateral Error: Absolute difference in left/right direction (steering prediction)
- Models should show decreasing loss over epochs
- Models should generalize to validation set

## Submission Requirements
- Maximum 60MB bundle size
- Include all model files, training scripts, and custom code
- No large datasets, temporary files, or IDE-specific files
- Include UT ID in bundle filename
- All code must run without errors

## Optional Bonus Evaluation
- Models can be tested in actual SuperTuxKart driving simulation
- Optional matplotlib visualizations of driving performance
- Bonus points for effective custom data transformations 