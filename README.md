# COVID-19 Severity Prediction using Temporal Fusion Transformer

A comprehensive machine learning project for predicting COVID-19 severity outcomes using multi-modal patient data and Temporal Fusion Transformer (TFT) architecture.

## ðŸŽ¯ Project Overview

This project implements a **4-day sprint methodology** to rapidly develop a Temporal Fusion Transformer model for COVID-19 severity prediction. The model predicts multiple clinical outcomes simultaneously:

- **Mortality Risk** (Binary Classification)
- **ICU Admission** (Binary Classification) 
- **Ventilator Need** (Binary Classification)
- **Length of Stay** (Regression)

## ðŸ—ï¸ Architecture

### Multi-Modal Data Integration
- **Static Features** (15 dimensions): Demographics, comorbidities, socioeconomic factors
- **Temporal Features** (50 dimensions): Vital signs, laboratory values, medications, procedures, devices

### TFT Model Specifications
- **Backbone**: `pytorch_forecasting.TemporalFusionTransformer`
- **Hidden Size**: 128 (configurable)
- **Attention Heads**: 4 (configurable)
- **Sequence Length**: Max 720 hours (30 days)
- **Multi-Task Heads**: 4 separate prediction heads with weighted loss

## ðŸ“ Project Structure

```
covid19-tft-severity-prediction/
â”œâ”€â”€ src/
â”‚   â”œâ”€â”€ data/
â”‚   â”‚   â”œâ”€â”€ synthea_loader.py      # Data loading and validation
â”‚   â”‚   â”œâ”€â”€ timeline_builder.py    # Patient temporal sequences
â”‚   â”‚   â”œâ”€â”€ feature_engineer.py    # Feature engineering
â”‚   â”‚   â””â”€â”€ data_validator.py      # Data quality checks
â”‚   â”œâ”€â”€ models/
â”‚   â”‚   â”œâ”€â”€ tft_model.py          # TFT model implementation
â”‚   â”‚   â”œâ”€â”€ loss_functions.py     # Multi-task loss functions
â”‚   â”‚   â””â”€â”€ baseline_models.py    # Baseline model comparisons
â”‚   â”œâ”€â”€ training/
â”‚   â”‚   â”œâ”€â”€ trainer.py            # Training pipeline
â”‚   â”‚   â”œâ”€â”€ callbacks.py          # Custom callbacks
â”‚   â”‚   â””â”€â”€ metrics.py            # Evaluation metrics
â”‚   â””â”€â”€ evaluation/
â”‚       â”œâ”€â”€ evaluator.py          # Model evaluation
â”‚       â”‚   â”œâ”€â”€ attention_analysis.py  # Attention pattern analysis
â”‚       â””â”€â”€ clinical_validation.py     # Clinical validation
â”œâ”€â”€ configs/
â”‚   â”œâ”€â”€ model_config.yaml         # Model architecture config
â”‚   â”œâ”€â”€ training_config.yaml      # Training parameters
â”‚   â””â”€â”€ data_config.yaml          # Data processing config
â”œâ”€â”€ notebooks/
â”‚   â”œâ”€â”€ data_exploration.ipynb   # Data analysis
â”‚   â”œâ”€â”€ model_development.ipynb   # Model development
â”‚   â””â”€â”€ results_analysis.ipynb    # Results analysis
â”œâ”€â”€ experiments/
â”‚   â”œâ”€â”€ baseline_experiments/     # Baseline model results
â”‚   â”œâ”€â”€ tft_experiments/         # TFT model results
â”‚   â”œâ”€â”€ results/                 # Final results
â”‚   â””â”€â”€ checkpoints/             # Model checkpoints
â”œâ”€â”€ data/
â”‚   â”œâ”€â”€ processed/               # Processed data
â”‚   â””â”€â”€ cache/                   # Data cache
â””â”€â”€ 10k_synthea_covid19_csv/    # Raw Synthea dataset
```

## ðŸš€ Quick Start

### 1. Environment Setup
```bash
# Clone the repository
git clone https://github.com/nitin2468git/MultiModal-Severity-Prediction-TemporalFusionTransformer.git
cd MultiModal-Severity-Prediction-TemporalFusionTransformer

# Activate virtual environment
source activate_env.sh

# Or manually:
python -m venv covid19_tft_env
source covid19_tft_env/bin/activate  # On Windows: covid19_tft_env\Scripts\activate
pip install -r requirements.txt
```

### 2. Data Loading
```python
from src.data.synthea_loader import SyntheaLoader

# Load and validate data
loader = SyntheaLoader("10k_synthea_covid19_csv")
tables = loader.load_all_tables()
covid19_patients = loader.identify_covid19_patients()
quality_metrics = loader.validate_data_quality()
```

### 3. Model Training
```python
from src.training.trainer import COVID19Trainer
from configs.training_config import load_config

# Load configuration
config = load_config("configs/training_config.yaml")

# Initialize trainer
trainer = COVID19Trainer(config)
trainer.train()
```

## ðŸ“Š Expected Results

### Performance Targets
- **Mortality AUROC**: > 0.85
- **ICU AUROC**: > 0.80  
- **Ventilator AUROC**: > 0.75
- **LOS RMSE**: < 5.0 days
- **Calibration**: ECE < 0.05

### Clinical Impact
- **Risk Stratification**: Clear thresholds for clinical action
- **Resource Allocation**: Optimization framework for healthcare resources
- **Treatment Timing**: Causal analysis for intervention windows
- **Uncertainty Communication**: Calibrated confidence intervals

## ðŸ”¬ Research Contributions

### Novel Features
- **Multi-Modal Integration**: Static + temporal patient data
- **Multi-Task Learning**: Simultaneous prediction of 4 outcomes
- **Attention-Based Causal Discovery**: Granger causality with attention weights
- **Uncertainty Quantification**: Bayesian methods for calibrated predictions
- **Clinical Interpretability**: Attention patterns aligned with medical knowledge

### Technical Innovations
- **Temporal Fusion Transformer**: Adapted for healthcare time-series
- **Multi-Task Loss Function**: Weighted combination of clinical outcomes
- **Robust Data Processing**: Handle missing data and class imbalance
- **Scalable Architecture**: Support for 10,000+ patient datasets

## ðŸ“ˆ Development Timeline

### 4-Day Sprint Methodology

#### **Day 1: Data Pipeline Development**
- âœ… Environment setup and dependency installation
- âœ… Data exploration and quality assessment
- ðŸ”„ SyntheaLoader implementation
- ðŸ”„ TimelineBuilder implementation
- ðŸ”„ FeatureEngineer development
- ðŸ”„ TFTFormatter for PyTorch tensors

#### **Day 2: Model Implementation**
- ðŸ”„ TFT model architecture implementation
- ðŸ”„ Multi-task prediction heads
- ðŸ”„ Loss function development
- ðŸ”„ Training pipeline implementation
- ðŸ”„ PyTorch Lightning integration

#### **Day 3: Training and Evaluation**
- ðŸ”„ Hyperparameter tuning setup
- ðŸ”„ Cross-validation implementation
- ðŸ”„ Full model training (30-50 epochs)
- ðŸ”„ Evaluation pipeline implementation
- ðŸ”„ Attention analysis development

#### **Day 4: Results and Documentation**
- ðŸ”„ Final model evaluation
- ðŸ”„ Statistical analysis
- ðŸ”„ Paper writing (ACM format)
- ðŸ”„ Presentation creation
- ðŸ”„ Repository organization

## ðŸ› ï¸ Technical Stack

### Core Dependencies
- **PyTorch**: Deep learning framework
- **PyTorch Forecasting**: Temporal Fusion Transformer implementation
- **PyTorch Lightning**: Training framework
- **Pandas/NumPy**: Data manipulation
- **Scikit-learn**: Machine learning utilities

### Visualization & Analysis
- **Matplotlib/Seaborn**: Static visualizations
- **Plotly**: Interactive visualizations
- **Lifelines**: Survival analysis
- **Statsmodels**: Statistical analysis

### Development Tools
- **YAML**: Configuration management
- **Jupyter**: Interactive development
- **Git**: Version control
- **Docker**: Containerization (optional)

## ðŸ“‹ Requirements

### System Requirements
- **Python**: 3.8+
- **GPU**: RTX 3070 or equivalent (8GB VRAM)
- **RAM**: 16GB+
- **Storage**: 10GB+ for dataset and models

### Performance Requirements
- **Training Time**: < 4 hours on RTX 3070
- **Memory Usage**: < 8GB GPU VRAM
- **Inference Time**: < 500ms per patient prediction
- **Scalability**: Support for 10,000+ patient dataset

## ðŸ” Data Description

### Synthea COVID-19 Dataset
- **Source**: Synthea synthetic patient data
- **Size**: 10,000 synthetic patients
- **Tables**: 17 CSV files (patients, encounters, conditions, medications, etc.)
- **COVID-19 Patients**: ~9,106 identified patients
- **Temporal Coverage**: Variable length patient timelines

### Data Quality
- **Missing Data**: Handle up to 20% missing values
- **Class Imbalance**: Address through focal loss and sampling
- **Outliers**: Robust loss functions (Huber loss for regression)
- **Data Drift**: Monitor and detect distribution shifts

## ðŸ“š Documentation

### Key Documents
- **Design Document**: `tft_design_doc.md` - Comprehensive project blueprint
- **Architecture**: `tft_architecture.md` - Technical architecture details
- **Paper Layout**: `tft_paper_layout.md` - Research paper structure

### Configuration Files
- **Model Config**: `configs/model_config.yaml` - TFT architecture parameters
- **Training Config**: `configs/training_config.yaml` - Training pipeline settings
- **Data Config**: `configs/data_config.yaml` - Data processing parameters

## ðŸ¤ Contributing

### Development Guidelines
- Follow the 4-day sprint methodology
- Implement type hints and comprehensive documentation
- Ensure clinical relevance and interpretability
- Maintain code quality and testing standards
- Track experiments and results systematically

### Code Standards
- **Naming**: PascalCase for classes, snake_case for functions
- **Documentation**: Comprehensive docstrings with clinical context
- **Testing**: Unit tests for all components
- **Logging**: Structured logging with clinical relevance

## ðŸ“„ License

This project is licensed under the MIT License - see the LICENSE file for details.

## ðŸ‘¥ Contact

- **Repository**: https://github.com/nitin2468git/MultiModal-Severity-Prediction-TemporalFusionTransformer
- **Author**: Nitin Bhatnagar
- **Project**: COVID-19 TFT Severity Prediction

## ðŸ™ Acknowledgments

- **Synthea**: Synthetic patient data generation
- **PyTorch Forecasting**: Temporal Fusion Transformer implementation
- **PyTorch Lightning**: Training framework
- **Research Community**: COVID-19 clinical research contributions 