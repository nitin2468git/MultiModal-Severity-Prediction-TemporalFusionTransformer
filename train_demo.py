#!/usr/bin/env python3
"""
Demo training script for COVID-19 TFT Severity Prediction
Shows clear progress and runs faster for demonstration
"""

import sys
import os
from pathlib import Path
import logging
import yaml
import json
from datetime import datetime
import torch
import numpy as np
from tqdm import tqdm

# Add src to path
sys.path.append(str(Path(__file__).parent / "src"))

from models.tft_model import COVID19TFTModel
from training.trainer import COVID19Trainer
from evaluation.metrics import COVID19Metrics

def setup_logging():
    """Setup logging configuration."""
    # Create logs directory
    log_dir = Path("experiments/logs")
    log_dir.mkdir(parents=True, exist_ok=True)
    
    logging.basicConfig(
        level=logging.INFO,
        format='%(asctime)s - %(levelname)s - %(message)s',
        handlers=[
            logging.FileHandler(log_dir / 'demo_training.log'),
            logging.StreamHandler()
        ]
    )

def create_demo_data():
    """Create demo data for faster training."""
    print("Creating demo dataset...")
    
    # Create synthetic data
    num_patients = 100  # Smaller dataset for demo
    seq_len = 100
    static_dim = 15
    temporal_dim = 50
    
    # Create static features
    static_features = torch.randn(num_patients, static_dim)
    
    # Create temporal features
    temporal_features = torch.randn(num_patients, seq_len, temporal_dim)
    
    # Create time indices
    time_index = torch.arange(seq_len).unsqueeze(0).expand(num_patients, -1).float()
    
    # Create targets
    mortality_risk = torch.randint(0, 2, (num_patients,)).float()
    icu_admission = torch.randint(0, 2, (num_patients,)).float()
    ventilator_need = torch.randint(0, 2, (num_patients,)).float()
    length_of_stay = torch.randn(num_patients,) * 24 + 72  # Mean 72 hours
    
    # Create demo dataset
    demo_data = []
    for i in range(num_patients):
        sample = {
            'static_features': static_features[i],
            'temporal_features': temporal_features[i],
            'time_index': time_index[i],
            'mortality_risk': mortality_risk[i],
            'icu_admission': icu_admission[i],
            'ventilator_need': ventilator_need[i],
            'length_of_stay': length_of_stay[i]
        }
        demo_data.append(sample)
    
    # Split into train/val/test
    train_size = int(0.7 * num_patients)
    val_size = int(0.15 * num_patients)
    
    train_data = demo_data[:train_size]
    val_data = demo_data[train_size:train_size + val_size]
    test_data = demo_data[train_size + val_size:]
    
    print(f"Demo dataset created:")
    print(f"  - Train: {len(train_data)} patients")
    print(f"  - Validation: {len(val_data)} patients")
    print(f"  - Test: {len(test_data)} patients")
    
    return train_data, val_data, test_data

def create_demo_dataloader(data, batch_size=8):
    """Create a simple dataloader for demo data."""
    from torch.utils.data import DataLoader, Dataset
    
    class DemoDataset(Dataset):
        def __init__(self, data):
            self.data = data
        
        def __len__(self):
            return len(self.data)
        
        def __getitem__(self, idx):
            return self.data[idx]
    
    dataset = DemoDataset(data)
    return DataLoader(dataset, batch_size=batch_size, shuffle=True)

def train_demo_model():
    """Train the model with demo data."""
    print("="*60)
    print("COVID-19 TFT DEMO TRAINING")
    print("="*60)
    
    # Setup logging
    setup_logging()
    logger = logging.getLogger(__name__)
    
    try:
        # Step 1: Create demo data
        logger.info("Step 1: Creating demo dataset")
        train_data, val_data, test_data = create_demo_data()
        
        # Step 2: Setup model
        logger.info("Step 2: Setting up model")
        with open("configs/model_config.yaml", 'r') as f:
            model_config = yaml.safe_load(f)
        
        trainer = COVID19Trainer()
        trainer.setup_model()
        
        model_info = trainer.model.get_model_info()
        logger.info(f"Model initialized: {model_info['total_parameters']:,} parameters")
        
        # Step 3: Create data loaders
        logger.info("Step 3: Creating data loaders")
        train_loader = create_demo_dataloader(train_data, batch_size=8)
        val_loader = create_demo_dataloader(val_data, batch_size=8)
        test_loader = create_demo_dataloader(test_data, batch_size=8)
        
        logger.info(f"Data loaders created:")
        logger.info(f"  - Train batches: {len(train_loader)}")
        logger.info(f"  - Validation batches: {len(val_loader)}")
        logger.info(f"  - Test batches: {len(test_loader)}")
        
        # Step 4: Training with progress display
        logger.info("Step 4: Starting training")
        
        # Training loop with clear progress
        num_epochs = 10  # Fewer epochs for demo
        best_val_loss = float('inf')
        patience = 3
        patience_counter = 0
        
        print("\n" + "="*50)
        print("TRAINING PROGRESS")
        print("="*50)
        
        for epoch in range(num_epochs):
            # Training
            trainer.model.train()
            train_loss = 0.0
            train_batches = 0
            
            print(f"\nEpoch {epoch + 1}/{num_epochs}")
            print("-" * 30)
            
            # Training loop with progress bar
            for batch_idx, batch in enumerate(tqdm(train_loader, desc="Training", leave=False)):
                # Move batch to device
                batch = {k: v.to(trainer.device) if isinstance(v, torch.Tensor) else v for k, v in batch.items()}
                
                # Forward pass
                trainer.optimizer.zero_grad()
                predictions = trainer.model(batch)
                
                # Compute loss
                targets = {k: batch[k] for k in ['mortality_risk', 'icu_admission', 'ventilator_need', 'length_of_stay'] if k in batch}
                losses = trainer.model.compute_loss(predictions, targets)
                
                # Backward pass
                losses['total_loss'].backward()
                trainer.optimizer.step()
                
                train_loss += losses['total_loss'].item()
                train_batches += 1
            
            avg_train_loss = train_loss / train_batches
            
            # Validation
            trainer.model.eval()
            val_loss = 0.0
            val_batches = 0
            
            with torch.no_grad():
                for batch in tqdm(val_loader, desc="Validation", leave=False):
                    batch = {k: v.to(trainer.device) if isinstance(v, torch.Tensor) else v for k, v in batch.items()}
                    
                    predictions = trainer.model(batch)
                    targets = {k: batch[k] for k in ['mortality_risk', 'icu_admission', 'ventilator_need', 'length_of_stay'] if k in batch}
                    losses = trainer.model.compute_loss(predictions, targets)
                    
                    val_loss += losses['total_loss'].item()
                    val_batches += 1
            
            avg_val_loss = val_loss / val_batches
            
            # Update scheduler
            if trainer.scheduler:
                trainer.scheduler.step()
            
            # Print progress
            current_lr = trainer.optimizer.param_groups[0]['lr']
            print(f"Train Loss: {avg_train_loss:.4f} | Val Loss: {avg_val_loss:.4f} | LR: {current_lr:.6f}")
            
            # Checkpointing
            if avg_val_loss < best_val_loss:
                best_val_loss = avg_val_loss
                patience_counter = 0
                trainer.save_checkpoint('demo_best_model.pth', epoch, avg_val_loss)
                print(f"âœ“ New best validation loss: {avg_val_loss:.4f}")
            else:
                patience_counter += 1
            
            # Early stopping
            if patience_counter >= patience:
                print(f"Early stopping triggered after {patience} epochs without improvement")
                break
        
        # Step 5: Final evaluation
        logger.info("Step 5: Final evaluation")
        
        # Load best model
        best_checkpoint_path = Path(trainer.config['checkpointing']['save_dir']) / 'demo_best_model.pth'
        if best_checkpoint_path.exists():
            trainer.load_checkpoint(str(best_checkpoint_path))
            logger.info("Loaded best model for final evaluation")
        
        # Make predictions on test set
        test_predictions = trainer.predict(test_loader)
        
        # Extract targets from test loader
        test_targets = {task: [] for task in ['mortality_risk', 'icu_admission', 'ventilator_need', 'length_of_stay']}
        for batch in test_loader:
            for task in test_targets.keys():
                if task in batch:
                    test_targets[task].extend(batch[task].cpu().numpy())
        
        # Convert to numpy arrays
        for task in test_targets:
            test_targets[task] = np.array(test_targets[task])
        
        # Calculate final metrics
        metrics_calculator = COVID19Metrics()
        final_metrics = metrics_calculator.calculate_metrics(test_predictions, test_targets)
        
        # Print final results
        print("\n" + "="*50)
        print("DEMO TRAINING COMPLETED!")
        print("="*50)
        print(f"Best validation loss: {best_val_loss:.4f}")
        print(f"Final epoch: {epoch + 1}")
        
        print("\nFinal Test Metrics:")
        print(f"  Mortality Risk AUROC: {final_metrics.get('mortality_risk_auroc', 0):.3f}")
        print(f"  ICU Admission AUROC: {final_metrics.get('icu_admission_auroc', 0):.3f}")
        print(f"  Ventilator Need AUROC: {final_metrics.get('ventilator_need_auroc', 0):.3f}")
        print(f"  Length of Stay MAE: {final_metrics.get('length_of_stay_mae', 0):.2f} hours")
        print(f"  Average AUROC: {final_metrics.get('average_auroc', 0):.3f}")
        
        print("\nClinical Interpretation:")
        clinical_interpretation = {
            'mortality_risk': "Demo model shows learning capability",
            'icu_admission': "Binary classification working",
            'ventilator_need': "Multi-task learning successful",
            'length_of_stay': "Regression task functioning"
        }
        
        for task, interpretation in clinical_interpretation.items():
            print(f"  {task.replace('_', ' ').title()}: {interpretation}")
        
        print("="*50)
        
        return {
            'best_val_loss': best_val_loss,
            'final_epoch': epoch + 1,
            'final_metrics': final_metrics,
            'model_info': model_info
        }
        
    except Exception as e:
        logger.error(f"Demo training failed: {e}")
        raise

if __name__ == "__main__":
    results = train_demo_model() 